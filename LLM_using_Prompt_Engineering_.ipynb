{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q635w5iIut9",
        "outputId": "2a4329a7-959c-4f8d-cabd-e6ed020b7fdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m374.1/374.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install openai -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.chatcompletion.create(model = '', messages = [{}])"
      ],
      "metadata": {
        "id": "GANlT47EI433"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = 'gpt-3.5-turbo'"
      ],
      "metadata": {
        "id": "jc5BtdvJI41j"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai -q"
      ],
      "metadata": {
        "id": "1S-ywFIuM4K8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "U8La7xi8M-vl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "# Set the API key\n",
        "openai.api_key = \"open-api-key\"\n",
        "if openai.api_key is None:\n",
        "  raise ValueError(\"OpenAI API key not found in environment variables.\")\n",
        "messages = [{'role':'user', 'content':'tell me a joke'}]\n",
        "response = openai.chat.completions.create(model = model, messages = messages)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbA1Zvt1Mgc4",
        "outputId": "fb2bf078-ef2f-4cfe-ec41-4a873cf3284a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-A7l6gQhJxNiRPkMJXMW5MvrjjXKf7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Why was the math book sad?\\n\\nBecause it had too many problems.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1726412738, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=14, prompt_tokens=11, total_tokens=25, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyTg4F3kOBae",
        "outputId": "64496544-7e2d-48c1-ab56-d14487328812"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why was the math book sad?\n",
            "\n",
            "Because it had too many problems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message = [{'role':'system', 'content':'You are an assistant that speaks like Shakespeare.'},{'role':'user','content':'tell me a joke'}]"
      ],
      "metadata": {
        "id": "ZrZFEQQBMga-"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.chat.completions.create(model = model, messages = messages)"
      ],
      "metadata": {
        "id": "IeWFzdCkO7HO"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0oSKZ1LMgOR",
        "outputId": "9b3c9528-a790-422a-cbe1-db07d04f6886"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-A7lC2PzuiNhN1YL3OGPv2IFWhNtqs', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Why couldn't the bicycle find its way home? Because it lost its bearings!\", refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1726413070, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=16, prompt_tokens=11, total_tokens=27, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7u2TfF9aMgK4",
        "outputId": "6c750294-1891-4c8a-b48b-f6f729542ea0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why couldn't the bicycle find its way home? Because it lost its bearings!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define  a function\n",
        "def get_response(promt, model = 'gpt-3.5-turbo'):\n",
        "  messages = [{'role':'user', 'content':promt}]\n",
        "  response = openai.chat.completions.create(model = model, messages = messages)\n",
        "  return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "IFUFDWNDPUl3"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'write a short blog on RAG (Retriveal Augmented Generated) limited to 500 words includes title, important topics, conclusion'\n",
        "response = get_response(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EwwNQPWPjdu",
        "outputId": "dfa20857-61b8-4b4d-f7ec-fe02000607f9"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: How RAG Technology is Revolutionizing Information Retrieval\n",
            "\n",
            "Information retrieval is a critical component of today's data-driven world, and advancements in technology are constantly reshaping how we access and organize information. One such innovation that is quickly gaining traction is the RAG (Retrieval Augmented Generated) technology. In this blog, we'll explore what RAG is, how it works, and its implications for the future of information retrieval.\n",
            "\n",
            "RAG combines the power of retrieval and generation models to provide more accurate and relevant information to users. Retrieval models are typically used to retrieve information based on specific keywords or queries, while generation models are used to create new text based on a prompt. By combining these two approaches, RAG is able to retrieve relevant information and generate new content in real-time, making it a powerful tool for information retrieval.\n",
            "\n",
            "One of the key features of RAG is its ability to generate responses to complex queries that traditional retrieval models may struggle to handle. For example, if a user inputs a question that requires a contextual understanding of a topic, RAG can generate a response that synthesizes information from multiple sources to provide a comprehensive answer. This is especially useful for tasks such as question-answering, natural language understanding, and content creation.\n",
            "\n",
            "Another important aspect of RAG is its ability to learn and improve over time. By continuously training the retrieval and generation models on new data, RAG can adapt to changing information needs and provide more accurate results. This means that users can benefit from an increasingly personalized and relevant information retrieval experience.\n",
            "\n",
            "The implications of RAG for information retrieval are significant. As more and more data becomes available online, the ability to quickly and accurately retrieve and generate information is essential for staying informed and making informed decisions. RAG has the potential to revolutionize how we interact with information, providing a more seamless and intuitive experience for users.\n",
            "\n",
            "In conclusion, RAG technology is an exciting development in the field of information retrieval. By combining the power of retrieval and generation models, RAG offers a more accurate and comprehensive approach to accessing and organizing information. As this technology continues to evolve and improve, we can expect to see significant advancements in how we interact with information in the digital age. If you're interested in staying ahead of the curve in information retrieval, RAG is definitely a technology to keep an eye on.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keep context - enabling conversation"
      ],
      "metadata": {
        "id": "L9CHSlfwQcIm"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_prompt_input = 'write a short blog on RAG (Retriveal Augmented Generated) limited to 500 words includes title, important topics, conclusion'"
      ],
      "metadata": {
        "id": "7MFfZQNGRJcW"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_prompt_output  = '''Title: How RAG Technology is Revolutionizing Information Retrieval\n",
        "\n",
        "Information retrieval is a critical component of today's data-driven world, and advancements in technology are constantly reshaping how we access and organize information. One such innovation that is quickly gaining traction is the RAG (Retrieval Augmented Generated) technology. In this blog, we'll explore what RAG is, how it works, and its implications for the future of information retrieval.\n",
        "\n",
        "RAG combines the power of retrieval and generation models to provide more accurate and relevant information to users. Retrieval models are typically used to retrieve information based on specific keywords or queries, while generation models are used to create new text based on a prompt. By combining these two approaches, RAG is able to retrieve relevant information and generate new content in real-time, making it a powerful tool for information retrieval.\n",
        "\n",
        "One of the key features of RAG is its ability to generate responses to complex queries that traditional retrieval models may struggle to handle. For example, if a user inputs a question that requires a contextual understanding of a topic, RAG can generate a response that synthesizes information from multiple sources to provide a comprehensive answer. This is especially useful for tasks such as question-answering, natural language understanding, and content creation.\n",
        "\n",
        "Another important aspect of RAG is its ability to learn and improve over time. By continuously training the retrieval and generation models on new data, RAG can adapt to changing information needs and provide more accurate results. This means that users can benefit from an increasingly personalized and relevant information retrieval experience.\n",
        "\n",
        "The implications of RAG for information retrieval are significant. As more and more data becomes available online, the ability to quickly and accurately retrieve and generate information is essential for staying informed and making informed decisions. RAG has the potential to revolutionize how we interact with information, providing a more seamless and intuitive experience for users.\n",
        "\n",
        "In conclusion, RAG technology is an exciting development in the field of information retrieval. By combining the power of retrieval and generation models, RAG offers a more accurate and comprehensive approach to accessing and organizing information. As this technology continues to evolve and improve, we can expect to see significant advancements in how we interact with information in the digital age. If you're interested in staying ahead of the curve in information retrieval, RAG is definitely a technology to keep an eye on.'''"
      ],
      "metadata": {
        "id": "tS0WVND6Qiph"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_prompt = \"Include 10 FAQs for the above blog post along with the answers\""
      ],
      "metadata": {
        "id": "kcy02SNAQimB"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{'role':'user', 'content':first_prompt_input},\n",
        "            {'role':'assistant','content':first_prompt_output},\n",
        "            {'role':'user','content':second_prompt}]"
      ],
      "metadata": {
        "id": "AXxNoeaLQijq"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.chat.completions.create(model = model, messages = messages)"
      ],
      "metadata": {
        "id": "uYg-E68lQihJ"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_promt_output = response.choices[0].message.content"
      ],
      "metadata": {
        "id": "51-UdgmfQiet"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "third_prompt = ''"
      ],
      "metadata": {
        "id": "gUM-HVz9TwLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{'role':'user', 'content':first_prompt_input},\n",
        "            {'role':'assistant','content':first_prompt_output},\n",
        "            {'role':'user','content':second_prompt},\n",
        "            {'role':'assistant','content':second_promt_output},\n",
        "            {'role':'user','content':third_prompt}\n",
        "            ]"
      ],
      "metadata": {
        "id": "igZ7MvDwTzI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define chat function as we cannot manually add each and every input and output"
      ],
      "metadata": {
        "id": "t6Pb75cYTzFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = []\n",
        "\n",
        "def chat(user_promt, is_clear = False):\n",
        "  global history\n",
        "  if is_clear:\n",
        "    history = []\n",
        "  input_message = {'role':'user', 'content':user_promt}\n",
        "  history.append(input_message)\n",
        "\n",
        "  response = openai.chat.completions.create(model = 'gpt-3.5-turbo', messages = history)\n",
        "  output_message = {'role':'assistant', 'content':response.choices[0].message.content}\n",
        "  history.append(output_message)\n",
        "  return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "E00IUHazTzDb"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"Write a welcome message for personal blog\"\n",
        "print(chat(user_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ame0SIekTzBN",
        "outputId": "87acd4be-b0ac-4c73-e896-4c00f3c7bfab"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to my personal blog! I am so excited to share my thoughts, experiences, and ideas with you. This space is a reflection of who I am and what I am passionate about. I hope you find inspiration, motivation, and a sense of connection as you explore the posts here. Thank you for joining me on this journey!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"Along with the welcome message, share some specific steps for person to give their thoughts/comments\"\n",
        "print(chat(user_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0Ta9WhRTy-z",
        "outputId": "f8482fc0-965b-4b7e-cca7-75803ab712a4"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am thrilled to have you here on my personal blog! Your thoughts and comments are highly valued and I would love to hear from you. Here are some steps on how you can share your thoughts and comments:\n",
            "\n",
            "1. Scroll down to the end of a blog post where you will find a comment section.\n",
            "2. Click on the comment section and type in your thoughts, feedback, or questions.\n",
            "3. Make sure to use a respectful tone and engage in constructive conversations.\n",
            "4. Feel free to share your own personal experiences or stories related to the blog post topic.\n",
            "5. You can also connect with me on social media or via email if you prefer to share your thoughts privately.\n",
            "\n",
            "I can't wait to hear from you and engage in meaningful discussions with my readers. Thank you for being a part of this community!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"Add a story to this message that how previous people has shared their comments, end the comments with jovial\"\n",
        "print(chat(user_prompt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBznvLayTy8R",
        "outputId": "e812ef08-4415-4766-bd30-ca08566ab92b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One of the most heartwarming experiences I've had with this blog was when a reader shared a personal story in the comments section of a post. It was a story about overcoming adversity and finding inner strength, and it touched the hearts of many other readers who chimed in with words of encouragement and support. Seeing the community come together to uplift one another was truly a beautiful moment that reminded me of the power of storytelling and human connection.\n",
            "\n",
            "So, don't hesitate to share your thoughts, stories, or even just a friendly hello in the comments section. Let's create a space where we can learn from each other, uplift one another, and share a few laughs along the way. Your voice matters, and I can't wait to hear from you! Let's make this blog a place filled with positivity and jovial moments. üòä\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for message in history:\n",
        "  print(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6VqgldJWbJr",
        "outputId": "cd531348-61b8-46b9-e055-4e86c3d4cd1a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'role': 'user', 'content': 'Write a welcome message for personal blog with projects'}\n",
            "{'role': 'assistant', 'content': 'Welcome to my personal blog! Here you will find a collection of my projects, ideas, and creativity all in one place. I am excited to share my journey with you and showcase the work that I am passionate about. I hope that you find inspiration and enjoyment in exploring my blog. Thank you for joining me on this adventure!'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"Write a welcome message for personal blog with projects\"\n",
        "print(chat(user_prompt, True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1O1VBhacWlZv",
        "outputId": "28916581-a61a-4dd5-efba-45bfa1e3b488"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to my personal blog! Here you will find a collection of my projects, ideas, and creativity all in one place. I am excited to share my journey with you and showcase the work that I am passionate about. I hope that you find inspiration and enjoyment in exploring my blog. Thank you for joining me on this adventure!\n"
          ]
        }
      ]
    }
  ]
}